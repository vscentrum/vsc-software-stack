easyblock = 'PythonBundle'

name = 'synthcity'
version = '0.2.10'

local_pytorch_version = '2.1.2'

homepage = 'https://github.com/vanderschaarlab/synthcity'
description = """A library for generating and evaluating synthetic tabular data."""

toolchain = {'name': 'foss', 'version': '2023a'}

# DEPS:
    # importlib-metadata - ok in pypi bundle
    # pandas>=1.4,<2 - in scipy is pandas v2.0.3 -> unpin
    # torch>=1.10.0,<2.0 - torch is v2.1.2 -> unpin
    # scikit-learn>=1.2 OK
    # nflows>=0.14 ok exts
    # numpy>=1.20, <1.24 - v1.25.1 in scipy -> unpin
    # lifelines>=0.27,!= 0.27.5, <0.27.8 -> NO -> created OK
    # opacus>=1.3 ok exts
    # decaf-synthetic-data>=0.1.6 ok exts
    # optuna>=3.1 OK
    # shap OK
    # tqdm OK
    # loguru ok exts
    # pydantic<2.0 - v2.5.3 -> unpin
    # cloudpickle - ok in SHAP
    # scipy ok
    # xgboost<2.0.0 - v2.0.2 -> unpin -> error -> try build v1.7.2 and use it
    # geomloss ok exts
    # pgmpy ok exts
        # networkx OK
        # pyparsing ok in pypi bundle
        # statsmodels OK
        # joblib ok in pypi bundle
    # redis OK
    # pycox ok exts
    # xgbse ok exts
    # pykeops ok exts
    # fflows ok exts 
    # monai OK
    # tsai; python_version>"3.7" ok exts
    # be-great>=0.0.5;python_version>="3.9" ok exts
    # arfpy ok exts
    #
    # opacus 1.4.1 requires opt-einsum, ok
    # be-great 0.0.7 requires accelerate, ok
    # be-great 0.0.7 requires datasets, OK (HF-Datasets)
    # be-great 0.0.7 requires transformers, OK (Transformers)
    # pgmpy 0.1.25 requires opt-einsum, ok
    # pykeops 2.2.3 requires keopscore, ok
    # tsai 0.3.9 requires fastai, -> UPDATE
    # tsai 0.3.9 requires imbalanced-learn, OK
    # tsai 0.3.9 requires pyts, ok
    # decaf-synthetic-data 0.1.6 requires pytorch-lightning OK
    # decaf-synthetic-data 0.1.6 requires torchtext -> add PyTorch-bundle instead of PyTorch -> has torchtext OK
    # pycox 0.2.3 requires feather-format, ok
    # pycox 0.2.3 requires h5py, OK
    # pycox 0.2.3 requires py7zr, ok
    # pycox 0.2.3 requires torchtuples, ok
    # -> unpin in local_preinstallopts
        # synthcity 0.2.10 has requirement lifelines!=0.27.5,<0.27.8,>=0.27, but you have lifelines 0.28
        # synthcity 0.2.10 has requirement numpy<1.24,>=1.20, but you have numpy 1.25.1.
        # synthcity 0.2.10 has requirement pandas<2,>=1.4, but you have pandas 2.0.3.
        # synthcity 0.2.10 has requirement pydantic<2.0, but you have pydantic 2.5.3.
        # synthcity 0.2.10 has requirement torch<2.0,>=1.10.0, but you have torch 2.1.2.
        # synthcity 0.2.10 has requirement xgboost<2.0.0, but you have xgboost 2.0.2.
    # -> networkx v2.8.8 in exts
        # decaf-synthetic-data 0.1.6 has requirement networkx<3.0,>=2.0, but you have networkx 3.1.
    # -> use xgbse v0.2.3
        # xgbse 0.3.1 has requirement joblib<2.0.0,>=1.4.2, but you have joblib 1.2.0.
        # xgbse 0.3.1 has requirement lifelines<0.30.0,>=0.29.0, but you have lifelines 0.28.0.
        # xgbse 0.3.1 has requirement numpy<2.0.0,>=1.26.4, but you have numpy 1.25.1.
        # xgbse 0.3.1 has requirement scikit-learn<2.0.0,>=1.5.0, but you have scikit-learn 1.3.1.
        # xgbse 0.3.1 has requirement xgboost<3.0.0,>=2.1.0, but you have xgboost 2.0.2.
    # py7zr 0.21.1 requires brotli, OK
    # py7zr 0.21.1 requires inflate64, ok
    # py7zr 0.21.1 requires multivolumefile, ok
    # py7zr 0.21.1 requires pybcj, ok
    # py7zr 0.21.1 requires pycryptodomex, ok
    # py7zr 0.21.1 requires pyppmd, ok
    # py7zr 0.21.1 requires pyzpyzstdstd, ok
    # py7zr 0.21.1 requires texttable, ok
    # decaf-synthetic-data 0.1.6 has requirement pytorch-lightning<2.0, but you have pytorch-lightning 2.2.1.
        # -> create econfig for Decaf
        # problem: decaf has only whl on pypi + no releases on GitHub
    # fastapi 0.110.0 has requirement typing-extensions>=4.8.0, but you have typing-extensions 4.6.3.
        # seems it goes from PyTorch-Lightning -> put it as the last dep
    # py7zr 0.21.1 has requirement brotli>=1.1.0; platform_python_implementation == "CPython", but you have brotli 1.0.9.
        # use v0.20.6
    # fastapi 0.110.0 has requirement typing-extensions>=4.8.0, but you have typing-extensions 4.6.3.
        # -> add v typing-extensions v4.9.0 to exts
    # py7zr 0.20.6 has requirement pyppmd<1.1.0,>=0.18.1, but you have pyppmd 1.1.0. -> add pyppmd v1.0.0 ok
    # TESTS
    # black 24.4.2 requires mypy-extensions ok exts
    # pre-commit 3.7.1 requires identify, ok exts
    # pre-commit 3.7.1 requires nodeenv, ok exts
    # bandit 1.7.9 requires stevedore, ok exts
    # pytest-benchmark 4.0.0 requires py-cpuinfo, OK
    # doc8 1.1.1 requires restructuredtext-lint, ok exts
    # doc8 1.1.1 requires stevedore, ok exts
    # flake8 7.1.0 requires mccabe, ok exts
    # flake8 7.1.0 requires pycodestyle, OK
    # flake8 7.1.0 requires pyflakes, ok exts
    # pre-commit 3.7.1 requires cfgv, ok exts
    # flake8 7.1.0 has requirement pycodestyle<2.13.0,>=2.12.0, but you have pycodestyle 2.11.1. -> flake8 v7.0.0
    
builddependencies = [('poetry', '1.5.1')]
dependencies = [
    ('Python', '3.11.3'),
    ('Python-bundle-PyPI', '2023.06'),
    ('lifelines', '0.28.0'),
    ('SciPy-bundle', '2023.07'),
    ('pydantic', '2.5.3'),
    ('Redis', '7.2.3'),
    ('scikit-learn', '1.3.1'),
    ('SHAP', '0.43.0'),
    ('PyTorch-bundle', local_pytorch_version),
    ('XGBoost', '1.7.2'),
    ('tqdm', '4.66.1'),
    ('HF-Datasets', '2.18.0'),
    ('Transformers', '4.39.3'),
    ('fastai', '2.7.15'),
    ('h5py', '3.9.0'),
    ('networkx', '3.1'),
    ('Brotli-python', '1.0.9'),
    ('statsmodels', '0.14.1'),
    ('imbalanced-learn', '0.12.3'),
    ('Optuna', '3.5.0'),
    ('MONAI', '1.3.0'),
    ('DECAF-synthetic-data', '0.1.6'),
    ('PyTorch-Lightning', '2.2.1'),
    # TESTS
    ('Jupyter-bundle', '20230823'),
    ('python-igraph', '0.11.4'),
    ('coverage', '7.2.3'),
    ('py-cpuinfo', '9.0.0'),
    ('pycodestyle', '2.11.1'),
    # ('pytest', '7.4.2'), in pypi bundle v7.4.0
    # ('pytest-xdist', '3.3.1'), in pypi bundle v3.3.1
]

sanity_pip_check = True
use_pip = True

# unpin deps restrictions
local_preinstallopts = (
    "sed -i"
    " -e 's/pandas>=1.4,<2/pandas>=1.4/'"
    " -e 's/torch>=1.10.0,<2.0/torch>=1.10.0/'"
    " -e 's/numpy>=1.20, <1.24/numpy>=1.20/'"
    " -e 's/pydantic<2.0/pydantic/'"
    # " -e 's/xgboost<2.0.0/xgboost/'"
    " -e 's/lifelines>=0.27,!= 0.27.5, <0.27.8/lifelines>=0.27,!= 0.27.5/'"
    " %(builddir)s/%(name)s/%(name)s-%(version)s/setup.cfg && "
    # fix pydantic.pydantic_core error in test_schema.py::test_schema_fail
    "sed -i"
    " -e '17 s/pydantic.pydantic_core._pydantic_core.ValidationError/pydantic_core._pydantic_core.ValidationError/'"
    " -e '3 a import pydantic_core'"
    " %(builddir)s/%(name)s/%(name)s-%(version)s/tests/plugins/core/test_schema.py && "
    # try to fix timegan error
    "sed -i"
    " -e '116 s/static_gen/static_gen, dtype=\"object\"/'"
    " -e '116 s/static_seed/static_seed, dtype=\"object\"/'"
    " %(builddir)s/%(name)s/%(name)s-%(version)s/tests/plugins/time_series/test_timegan.py && "
)

# fix invalid syntax of xgbse/setup.py
local_xgbse_preinstallopts = (
    "sed -i "
    " -e '45,49d'"
    " -e 's/pandas>=1.0.\*/pandas>=1.0.0/'"
    " setup.py && "
)

exts_list = [
    ('cfgv', '3.4.0', {
        'checksums': ['e52591d4c5f5dead8e0f673fb16db7949d2cfb3f7da4582893288f0ded8fe560'],
    }),
    ('pyflakes', '3.2.0', {
        'checksums': ['1c61603ff154621fb2a9172037d84dca3500def8c8b630657d1701f026f8af3f'],
    }),
    ('mccabe', '0.7.0', {
        'checksums': ['348e0240c33b60bbdf4e523192ef919f28cb2c3d7d5c7794f74009290f236325'],
    }),
    ('restructuredtext_lint', '1.4.0', {
        'checksums': ['1b235c0c922341ab6c530390892eb9e92f90b9b75046063e047cacfb0f050c45'],
    }),
    ('stevedore', '5.2.0', {
        'checksums': ['46b93ca40e1114cea93d738a6c1e365396981bb6bb78c27045b7587c9473544d'],
    }),
    ('nodeenv', '1.9.1', {
        'checksums': ['6ec12890a2dab7946721edbfbcd91f3319c6ccc9aec47be7c7e6b7011ee6645f'],
    }),
    ('identify', '2.6.0', {
        'checksums': ['cb171c685bdc31bcc4c1734698736a7d5b6c8bf2e0c15117f4d469c8640ae5cf'],
    }),
    ('mypy_extensions', '1.0.0', {
        'checksums': ['75dbf8955dc00442a438fc4d0666508a9a97b6bd41aa2f0ffe9d2f2725af0782'],
    }),
    ('pytest-cov', '5.0.0', {
        'checksums': ['5837b58e9f6ebd335b0f8060eecce69b662415b16dc503883a02f45dfeb14857'],
    }),
    ('bandit', '1.7.9', {
        'checksums': ['7c395a436743018f7be0a4cbb0a4ea9b902b6d87264ddecf8cfdc73b4f78ff61'],
    }),
    ('black', '24.4.2', {
        'checksums': ['c872b53057f000085da66a19c55d68f6f8ddcac2642392ad3a355878406fbd4d'],
    }),
    ('black-nb', '0.7', {
        'checksums': ['8742a4f7c728302c91954325168d779f9444f8e3c31b19598ee8e98fc4bf4782'],
    }),
    ('darglint', '1.8.1', {
        'checksums': ['080d5106df149b199822e7ee7deb9c012b49891538f14a11be681044f0bb20da'],
    }),
    ('doc8', '1.1.1', {
        'checksums': ['d97a93e8f5a2efc4713a0804657dedad83745cca4cd1d88de9186f77f9776004'],
    }),
    ('flake8', '7.0.0', {
        'checksums': ['33f96621059e65eec474169085dc92bf26e7b2d47366b70be2f67ab80dc25132'],
    }),
    ('isort', '5.13.2', {
        'checksums': ['48fdfcb9face5d58a4f6dde2e72a1fb8dcaf8ab26f95ab49fab84c2ddefb0109'],
    }),
    ('pytest-benchmark', '4.0.0', {
        'checksums': ['fb0785b83efe599a6a956361c0691ae1dbb5318018561af10f3e915caa0048d1'],
    }),
    ('pytest-xprocess', '1.0.2', {
        'modulename': 'xprocess',
        'checksums': ['15e270637586eabc56755ee5fcc81c48bdb46ba7ef7c0d5b1b64302d080cc60f'],
    }),
    ('pre_commit', '3.7.1', {
        'checksums': ['8ca3ad567bc78a4972a3f1a477e94a79d4597e8140a6e0b651c5e33899c3654a'],
    }),
    ('typing_extensions', '4.9.0', {
        'checksums': ['23478f88c37f27d76ac8aee6c905017a143b0b1b886c3c9f66bc2fd94f9f5783'],
    }),
    ('fflows', '0.0.3', {
        'source_tmpl': '%(name)s-%(version)s-py3-none-any.whl',
        'checksums': ['18de7a7b98e3708ff2d5ae9f10fad625740230c4de6447906b7ca477667b78fb'],
    }),
    ('geomloss', '0.2.6', {
        'checksums': ['491c47085c5001b2cb6128ea541fd2d0a8808ae50e88a0798c7853c9d995faeb'],
    }),
    ('nflows', '0.14', {
        'checksums': ['6299844a62f9999fcdf2d95cb2d01c091a50136bd17826e303aba646b2d11b55'],
    }),
    ('opt_einsum', '3.3.0', {
        'source_tmpl': '%(name)s-%(version)s-py3-none-any.whl',
        'checksums': ['2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147'],
    }),
    ('opacus', '1.4.1', {
        'source_tmpl': '%(name)s-%(version)s-py3-none-any.whl',
        'checksums': ['8c46aff596bbbc6025ce9d169b49d5b3112cb958e3d74f8b77274134e7590890'],
    }),
    ('pgmpy', '0.1.25', {
        'source_tmpl': '%(name)s-%(version)s-py3-none-any.whl',
        'checksums': ['7c4fb15e4c0fd0310160a6a77297d6db382bd18f6ff35fcd0458c3cbd42caf78'],
    }),
    ('feather-format', '0.4.1', {
        'modulename': 'feather',
        'checksums': ['45f67e3745d394d4f160ca6d636bbfd4f8b68d01199dc1649b6e487d3e878903'],
    }),
    ('inflate64', '1.0.0', {
        'checksums': ['3278827b803cf006a1df251f3e13374c7d26db779e5a33329cc11789b804bc2d'],
    }),
    ('multivolumefile', '0.2.3', {
        'source_tmpl': '%(name)s-%(version)s-py3-none-any.whl',
        'checksums': ['237f4353b60af1703087cf7725755a1f6fcaeeea48421e1896940cd1c920d678'],
    }),
    ('pybcj', '1.0.2', {
        'modulename': 'bcj',
        'checksums': ['c7f5bef7f47723c53420e377bc64d2553843bee8bcac5f0ad076ab1524780018'],
    }),
    ('pycryptodomex', '3.20.0', {
        'modulename': 'Crypto',
        'checksums': ['7a710b79baddd65b806402e14766c721aee8fb83381769c27920f26476276c1e'],
    }),
    ('pyppmd', '1.0.0', {
        'checksums': ['075c9bd297e3b0a87dd7aeabca7fee668218acbe69ecc1c6511064558de8840f'],
    }),
    ('pyzstd', '0.16.0', {
        'checksums': ['fd43a0ae38ae15223fb1057729001829c3336e90f4acf04cf12ebdec33346658'],
    }),
    ('texttable', '1.7.0', {
        'checksums': ['2d2068fb55115807d3ac77a4ca68fa48803e84ebb0ee2340f858107a36522638'],
    }),
    ('py7zr', '0.20.6', {
        'checksums': ['d036dee11fce69ad8d4fa86025ccfc4a3511ec27ee1c6b5bd8d6759313dbd077'],
    }),
    ('torchtuples', '0.2.2', {
        'source_tmpl': '%(name)s-%(version)s-py3-none-any.whl',
        'checksums': ['186625230a149cc09f64116d51b203ffefe78160f5a0445adad195893663f55b'],
    }),
    ('pycox', '0.2.3', {
        'source_tmpl': '%(name)s-%(version)s-py3-none-any.whl',
        'checksums': ['9ea3c64a4a650ccf6c96cf512712de330f2d75de32122d86995c7cd37ff105d1'],
    }),
    ('keopscore', '2.2.3', {
        'checksums': ['64d5dad1e8c806d7070cdc60e48fd5bbf006f2bf1afd39ad3fa5e9fb213517d2'],
    }),
    ('pykeops', '2.2.3', {
        'checksums': ['2e2cba1de5e05c35559957a14f41cb5165dc667cc51b3b2118d7e0027eb435a1'],
    }),
    ('pyts', '0.13.0', {
        'source_tmpl': '%(name)s-%(version)s-py3-none-any.whl',
        'checksums': ['b49608267b686ea693dba31316ef2b22ad73ea29b27144696c347809ecd5ad62'],
    }),
    ('tsai', '0.3.9', {
        'source_tmpl': '%(name)s-%(version)s-py3-none-any.whl',
        'checksums': ['0e6460e9ff075176c8af25ef90444ef2e287bc5fe5510e2a0f427e4d0b37ebc0'],
    }),
    ('accelerate', '0.32.1', {
        'checksums': ['3999acff0237cd0d4f9fd98b42d5a3163544777b53fc4f1eec886b77e992d177'],
    }),
    ('be_great', '0.0.7', {
        'source_tmpl': '%(name)s-%(version)s-py3-none-any.whl',
        'checksums': ['824f10482581f5211d3a435d8b14adcc6c21b38d952f00b6a792fc7c089788b1'],
    }),
    ('xgbse', '0.2.3', {
        'preinstallopts': "sed -i  -e '45,49d' -e 's/pandas>=1.0.\*/pandas>=1.0.0/' setup.py && ",
        'source_urls': ['https://github.com/loft-br/xgboost-survival-embeddings/archive/'],
        'sources': ['v%(version)s.tar.gz'],
        'checksums': ['9e6b71539b2b533c00eddfe7681cdd541f393d9573594eca358d263b141c127d'],
    }),
    ('arfpy', '0.1.1', {
        'checksums': ['88170d5e72638b0dbfec28cfbdfee02e97bd6a06d5a636e960acd5d90d480707'],
    }),
    (name, version, {
        'preinstallopts': "sed -i -e 's/pandas>=1.4,<2/pandas>=1.4/' -e 's/torch>=1.10.0,<2.0/torch>=1.10.0/' -e 's/numpy>=1.20, <1.24/numpy>=1.20/' -e 's/pydantic<2.0/pydantic/' -e 's/xgboost<2.0.0/xgboost/' -e 's/lifelines>=0.27,!= 0.27.5, <0.27.8/lifelines>=0.27,!= 0.27.5/' %(builddir)s/%(name)s/%(name)s-%(version)s/setup.cfg && ",
        'source_urls': ['https://github.com/vanderschaarlab/synthcity/archive/'],
        'sources': ['v%(version)s.tar.gz'],
        'testinstall': True,
        'runtest': 'export TOKENIZERS_PARALLELISM=true && pytest -vvvs -m "not slow" --durations=50',
        'checksums': ['122a8546cad35e3ac5c74cf81281252dec4dd3c7b1d7afe0f45ef785f89cc682'],
    }),
]

sanity_check_commands = [
    "python -c 'from synthcity.plugins import Plugins'",
    "python -c 'from decaf import DECAF, DataModule'"
]

moduleclass = 'lib'

# ERROR6:
    # -> created and used XGBoost v1.7.2 -> delete unpin from preinstallopts + use it in decaf
    # -> added 'export TOKENIZERS_PARALLELISM=true' to runtest to fix huggingface/tokenizers problem
    # -> pydantic_core problem -> added sed -i with import pydentic_core and fix the use of pydantic_core._pydantic_core.ValidationError
        # >>> from pydantic import pydantic_core
            # Traceback (most recent call last):
            # File "<stdin>", line 1, in <module>
            # ImportError: cannot import name 'pydantic_core' from 'pydantic' (/apps/gent/RHEL8/cascadelake-ib/software/pydantic/2.5.3-GCCcore-12.3.0/lib/python3.11/site-packages/pydantic/__init__.py)
        # >>> import pydantic_core
        # >>> import pydantic_core._pydantic_core.ValidationError
            # Traceback (most recent call last):
            # File "<stdin>", line 1, in <module>
            # ModuleNotFoundError: No module named 'pydantic_core._pydantic_core.ValidationError'; 'pydantic_core._pydantic_core' is not a package
        # >>> from pydantic_core import _pydantic_core.ValidationError
            # File "<stdin>", line 1
            # from pydantic_core import _pydantic_core.ValidationError
            # SyntaxError: invalid syntax
        # >>> from pydantic_core import _pydantic_core
        # >>> a = _pydantic_core.ValidationError
        # >>> print(a)
            # <class 'pydantic_core._pydantic_core.ValidationError'>
        # >>> from pydantic_core._pydantic_core import ValidationError
    
    # FROM test_log2.txt
        # tests/plugins/core/models/survival_analysis/test_surv_xgb.py::test_train_prediction FAILED
            # -> problem with xgboost version -> ok fixed
        
        # tests/plugins/core/models/dag/test_dag_sanity.py::test_sanity 
            # Training: |          | 0/? [00:00<?, ?it/s]
            # Training:   0%|          | 0/1 [00:00<?, ?it/s]
            # Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] 
            # Epoch 0: 100%|| 1/1 [00:03<00:00,  0.29it/s]
            # Epoch 0: 100%|| 1/1 [00:03<00:00,  0.29it/s, v_num=2.01e+7, mse_loss=0.723, dsl_loss=3.660, total_loss=4.380]
            # Epoch 0: 100%|| 1/1 [00:03<00:00,  0.29it/s, v_num=2.01e+7, mse_loss=0.723, dsl_loss=3.660, total_loss=4.380]
            # Epoch 0: 100%|| 1/1 [00:03<00:00,  0.29it/s, v_num=2.01e+7, mse_loss=0.723, dsl_loss=3.660, total_loss=4.380]
            # XFAIL -> ok expected to fail
        
        # tests/plugins/core/models/time_series_survival/test_ts_surv_xgb.py::test_train_prediction[Transformer] FAILED
            # -> change xgboost version should fix thix 
        
        # huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
        #     To disable this warning, you can either:
	    #     - Avoid using `tokenizers` before the fork if possible
	    #     - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
        #     /scratch/gent/vo/001/gvo00117/easybuild/RHEL8/cascadelake-ampere-ib/software/scikit-learn/1.3.1-gfbf-2023a/lib/python3.11/site-packages
        #     /sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target
        #     warnings.warn(msg, UserWarning)
        #     FAILED
            # -> should be fixed by set ... in testrun
        
        # tests/plugins/privacy/test_decaf.py::test_plugin_generate[test_plugin1]
        # 100%|| 1000/1000 [00:49<00:00, 20.18it/s]
        # /scratch/gent/vo/001/gvo00117/easybuild/RHEL8/cascadelake-ampere-ib/software/scikit-learn/1.3.1-gfbf-2023a/lib/python3.11/site-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target
        #     warnings.warn(msg, UserWarning)
        # FAILED
        
        # same for: tests/plugins/privacy/test_decaf.py::test_plugin_generate[test_plugin2] FAILED
        
        # -> for problem with sklearn look: https://stackoverflow.com/questions/76713605/using-mutual-info-classif-for-continuous-features-and-discrete-target
        
        # tests/plugins/privacy/test_dpgan.py::test_plugin_generate[True-test_plugin1] 
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # FAILED
        # tests/plugins/privacy/test_dpgan.py::test_plugin_generate[True-test_plugin2] 
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # FAILED
        # tests/plugins/privacy/test_dpgan.py::test_plugin_generate[False-test_plugin0] 
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # FAILED
        # tests/plugins/privacy/test_dpgan.py::test_plugin_generate[False-test_plugin1] 
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # FAILED
        # tests/plugins/privacy/test_dpgan.py::test_plugin_generate[False-test_plugin2] 
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # FAILED
        # tests/plugins/privacy/test_dpgan.py::test_plugin_generate_constraints[test_plugin0] 
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # FAILED
        # tests/plugins/privacy/test_dpgan.py::test_plugin_generate_constraints[test_plugin1] 
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # FAILED
        # tests/plugins/privacy/test_dpgan.py::test_plugin_generate_constraints[test_plugin2] 
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # FAILED
        # -> dpgan: https://github.com/vanderschaarlab/evaluating-generative-models/blob/093910e487d07959db7d87b54698da60aaeb50c0/requirements_dpgan.txt#L2

        # tests/plugins/time_series/test_timegan.py::test_plugin_generate_static_cond[source0] 
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # 10%|         | 1/10 [00:01<00:09,  1.07s/it]
        # 20%|        | 2/10 [00:02<00:08,  1.05s/it]
        # 30%|       | 3/10 [00:03<00:07,  1.05s/it]
        # 40%|      | 4/10 [00:04<00:06,  1.05s/it]
        # 50%|     | 5/10 [00:05<00:05,  1.05s/it]
        # 60%|    | 6/10 [00:06<00:04,  1.05s/it]
        # 70%|   | 7/10 [00:07<00:03,  1.05s/it]
        # 80%|  | 8/10 [00:08<00:02,  1.05s/it]
        # 90%| | 9/10 [00:09<00:01,  1.05s/it]
        # 100%|| 10/10 [00:10<00:00,  1.04s/it]
        # 100%|| 10/10 [00:10<00:00,  1.05s/it]
        # FAILED
        # tests/plugins/time_series/test_timegan.py::test_plugin_generate_static_cond[source1] 
        # 0%|          | 0/10 [00:00<?, ?it/s]
        # 10%|         | 1/10 [00:00<00:05,  1.66it/s]
        # 20%|        | 2/10 [00:01<00:04,  1.74it/s]
        # 30%|       | 3/10 [00:01<00:03,  1.75it/s]
        # 40%|      | 4/10 [00:02<00:03,  1.76it/s]
        # 50%|     | 5/10 [00:02<00:02,  1.77it/s]
        # 60%|    | 6/10 [00:03<00:02,  1.77it/s]
        # 70%|   | 7/10 [00:03<00:01,  1.78it/s]
        # 80%|  | 8/10 [00:04<00:01,  1.78it/s]
        # 90%| | 9/10 [00:05<00:00,  1.78it/s]
        # 100%|| 10/10 [00:05<00:00,  1.79it/s]
        # 100%|| 10/10 [00:05<00:00,  1.77it/s]
        # FAILED
        # -> timegan plugin in synthcity: https://github.com/vanderschaarlab/synthcity/blob/v0.2.10/src/synthcity/plugins/time_series/plugin_timegan.py
        
        # E  AttributeError: `best_iteration` is only defined when early stopping is used.
            # -> OK seems as problem with xgboost v2: https://github.com/microsoft/FLAML/issues/1217
        # E  AttributeError: module 'pydantic' has no attribute 'pydantic_core'
            # -> OK pydantic_core should be in pydantic, but replace pydantic.pydantic_core only by pydantic_core
        # E  AttributeError: 'DPOptimizer' object has no attribute '_optimizer_step_pre_hooks'
            # -> seems as a problem with PyTorch: https://github.com/pytorch/opacus/issues/377
            # or with the version: https://github.com/vanderschaarlab/synthcity/pull/168
            # but there is no pytorch < 2 for lates toolchains -> delete this test?
        # E  ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (50,) + inhomogeneous part.
            # -> problem with too new numpy? https://stackoverflow.com/questions/67183501/setting-an-array-element-with-a-sequence-requested-array-has-an-inhomogeneous-sh
            # FROM: https://stackoverflow.com/questions/67183501/setting-an-array-element-with-a-sequence-requested-array-has-an-inhomogeneous-sh
                # With dtype="object" it works for me. -> variable2 = np.asarray(variable1, dtype="object")
        # ============================================== short test summary info ===============================================
        # FAILED tests/metrics/test_performance.py::test_evaluate_performance_time_series_survival[PerformanceEvaluatorXGB-test_plugin0]
        # FAILED tests/plugins/core/test_schema.py::test_schema_fail - AttributeError: module 'pydantic' has no attribute 'py...
        # FAILED tests/plugins/core/models/survival_analysis/test_surv_xgb.py::test_train_prediction - AttributeError: `best_...
        # FAILED tests/plugins/core/models/time_series_survival/test_ts_surv_xgb.py::test_train_prediction[Transformer] - Att...
        # FAILED tests/plugins/core/models/time_to_event/test_tte_xgb.py::test_train_prediction - AttributeError: `best_itera...
        # FAILED tests/plugins/privacy/test_decaf.py::test_plugin_generate[test_plugin0] - RuntimeError: Training with multip...
        # FAILED tests/plugins/privacy/test_decaf.py::test_plugin_generate[test_plugin1] - RuntimeError: Training with multip...
        # FAILED tests/plugins/privacy/test_decaf.py::test_plugin_generate[test_plugin2] - RuntimeError: Training with multip...
        # FAILED tests/plugins/privacy/test_dpgan.py::test_plugin_generate[True-test_plugin1] - AttributeError: 'DPOptimizer'...
        # FAILED tests/plugins/privacy/test_dpgan.py::test_plugin_generate[True-test_plugin2] - AttributeError: 'DPOptimizer'...
        # FAILED tests/plugins/privacy/test_dpgan.py::test_plugin_generate[False-test_plugin0] - AttributeError: 'DPOptimizer...
        # FAILED tests/plugins/privacy/test_dpgan.py::test_plugin_generate[False-test_plugin1] - AttributeError: 'DPOptimizer...
        # FAILED tests/plugins/privacy/test_dpgan.py::test_plugin_generate[False-test_plugin2] - AttributeError: 'DPOptimizer...
        # FAILED tests/plugins/privacy/test_dpgan.py::test_plugin_generate_constraints[test_plugin0] - AttributeError: 'DPOpt...
        # FAILED tests/plugins/privacy/test_dpgan.py::test_plugin_generate_constraints[test_plugin1] - AttributeError: 'DPOpt...
        # FAILED tests/plugins/privacy/test_dpgan.py::test_plugin_generate_constraints[test_plugin2] - AttributeError: 'DPOpt...
        # FAILED tests/plugins/time_series/test_timegan.py::test_plugin_generate_static_cond[source0] - ValueError: setting a...
        # FAILED tests/plugins/time_series/test_timegan.py::test_plugin_generate_static_cond[source1] - ValueError: setting a...
        # ======== 18 failed, 2141 passed, 13 skipped, 103 deselected, 2 xfailed, 2316 warnings in 15511.26s (4:18:31) =========
             
# ERROR5: OK
    # -> Delete this - seems is not from synthcity but from others packages
    # Pytest in sanity check cmds:
        # ModuleNotFoundError: No module named 'cython_test_exception_raiser' ok
        # ModuleNotFoundError: No module named 'hamcrest' ok
        # No module named 'service_identity ok
        # twisted 24.3.0 requires automat, ok
        # twisted 24.3.0 requires constantly, ok
        # twisted 24.3.0 requires hyperlink, ok
        # twisted 24.3.0 requires zope-interface, ok
        # No module named 'incremental' ok
        # ModuleNotFoundError: No module named 'twisted' ok
        # ModuleNotFoundError: No module named 'fixtures' ok
        # ModuleNotFoundError: No module named 'hypothesis' OK
        # ModuleNotFoundError: No module named 'testscenarios' ok
        # ModuleNotFoundError: No module named 'testtools' ok
        # ModuleNotFoundError: No module named 'evaluate' ok
# ERROR4: OK
    # try runtest + 'testinstall': True
        # -> WORKS
    # maybe to postinstallcmds?
    # add to runtest: "export PYTHONPATH=%(installdir)s/lib/python%(pyshortver)s/site-packages:$PYTHONPATH &&" before pytest?
        # NO there is no synthcity in site-packages yet
    # add pytest cmd to sanity check cmds
        # seems it tests all the packages not only synthcity -> errors about modules etc
    # when runtest = 'pytest -vvvs -m "not slow" --durations=50'
        # = 2024-07-16 15:03:20,115 build_log.py:171 ERROR EasyBuild crashed with an error (at easybuild/easybuild-framework/easybuild/base/exceptions.py:126 in __init__): cmd "  pytest -vvvs -m "n slow" --durations=50 " exited with exit code 4 and output:
        # ImportError while loading conftest '/tmp/vsc47063/easybuild/build/synthcity/0.2.10/foss-2023a/synthcity/synthcity-0.2.10/tests/conftest.py'.
        # tests/conftest.py:10: in <module>
        #     from synthcity.utils.reproducibility import clear_cache, enable_reproducible_results
        # E   ModuleNotFoundError: No module named 'synthcity'
# ERROR3: OK
    # -> add coverage to deps
    # -> put runtest to exts - synthcity ext, not as runtest = ...
    # tests/test_pytest_cov.py:12: in <module>
    #     import coverage
    # E   ModuleNotFoundError: No module named 'coverage'
# ERROR2: OK
    # -> fix pandas version in setup.py by local_xgbse_preinstallopts
    # == 2024-07-15 14:17:49,585 build_log.py:171 ERROR EasyBuild crashed with an error (at easybuild/easybuild-framework/easybuild/base/exceptions.py:126 in __init__): cmd "sed -i '45,49d' setup.py &&  /apps/gent/RHEL8/zen2-ib/software/Python/3.11.3-GCCcore-12.3.0/bin/python -m pip install --prefix=/scratch/gent/vo/001/gvo00117/easybuild/RHEL8/zen2-ib/software/synthcity/0.2.10-foss-2023a  --no-deps  --ignore-installed  --no-index  --no-build-isolation  ." exited with exit code 1 and output:
    # Processing /tmp/vsc47063/easybuild/build/synthcity/0.2.10/foss-2023a/xgbse/xgboost-survival-embeddings-0.2.3
    #   Preparing metadata (setup.py): started
    #   Preparing metadata (setup.py): finished with status 'error'
    #   error: subprocess-exited-with-error
    
    #    python setup.py egg_info did not run successfully.
    #    exit code: 1
    #   > [3 lines of output]
    #       error in xgbse setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers; Expected end or semicolon (after version specifier)
    #           pandas>=1.0.*
    #                 ~~~~~^
    #       [end of output]
    
    #   note: This error originates from a subprocess, and is likely not a problem with pip.
    # error: metadata-generation-failed

    #  Encountered error while generating package metadata.
    # > See above for output.

    # note: This is an issue with the package mentioned above, not pip.
    # hint: See above for details.
# ERROR1: OK
    # -> add xgbse_preinstallopts to delete wrong part from setup.py
    # -> seems like a problem with pip and setuptools version: https://stackoverflow.com/questions/77124879/pip-extras-require-must-be-a-dictionary-whose-values-are-strings-or-lists-of
    # == 2024-07-15 13:57:09,544 build_log.py:171 ERROR EasyBuild crashed with an error (at easybuild/easybuild-framework/easybuild/base/exceptions.py:126 in __init__): cmd " /apps/gent/RHEL8/zen2-ib/software/Python/3.11.3-GCCcore-12.3.0/bin/python -m pip install --prefix=/scratch/gent/vo/001/gvo00117/easybuild/RHEL8/zen2-ib/software/synthcity/0.2.10-foss-2023a  --no-deps  --ignore-installed  --no-index  --no-build-isolation  ." exited with exit code 1 and output:
    # Processing /tmp/vsc47063/easybuild/build/synthcity/0.2.10/foss-2023a/xgbse/xgboost-survival-embeddings-0.2.3
    #   Preparing metadata (setup.py): started
    #   Preparing metadata (setup.py): finished with status 'error'
    #   error: subprocess-exited-with-error
    
    #    python setup.py egg_info did not run successfully.
    #    exit code: 1
    #   > [1 lines of output]
    #       error in xgbse setup command: 'extras_require' must be a dictionary whose values are strings or lists of strings containing valid project/version requirement specifiers.
    #       [end of output]
    
    #   note: This error originates from a subprocess, and is likely not a problem with pip.
    # error: metadata-generation-failed

    #  Encountered error while generating package metadata.
    # > See above for output.

    # note: This is an issue with the package mentioned above, not pip.
    # hint: See above for details.
